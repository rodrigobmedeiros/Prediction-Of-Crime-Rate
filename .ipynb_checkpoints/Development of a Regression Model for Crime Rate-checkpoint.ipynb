{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Esta análise é baseada no dataset `uscrime` -> [link to download](http://www.statsci.org/data/general/uscrime.txt).\n",
    "A ideia é desenvolver um modelo preditivo capaz de calcular a taxa de criminalidade baseado nas demais variáveis presentes no dataset.\n",
    "\n",
    "# Descrição\n",
    "\n",
    "Criminologistas estão interessados no efeito dos regimes de punição nas taxas de criminalidade. Isto foi estudado utilizando dados agregados de 47 estados dos EUA em 1960. O conjunto de dados contém as seguintes colunas:\n",
    "\n",
    "# Variável - Descrição\n",
    "\n",
    "- M - Percentage of males aged 14–24 in total state population.\n",
    "- So - Indicator variable for a southern state.\n",
    "- Ed - Mean years of schooling of the population aged 25 years or over.\n",
    "- Po1 - Per capita expenditure on police protection in 1960.\n",
    "- Po2 - Per capita expenditure on police protection in 1959.\n",
    "- LF - Labour force participation rate of civilian urban males in the age-group 14-24.\n",
    "- M.F - Number of males per 100 females.\n",
    "- Pop - State population in 1960 in hundred thousands.\n",
    "- NW - Percentage of nonwhites in the population.\n",
    "- U1 - Unemployment rate of urban males 14–24.\n",
    "- U2 - Unemployment rate of urban males 35–39.\n",
    "- Wealth - Median value of transferable assets or family income.\n",
    "- Ineq - Income inequality: percentage of families earning below half the median income.\n",
    "- Prob - Probability of imprisonment: ratio of number of commitments to number of offenses.\n",
    "- Time - Average time in months served by offenders in state prisons before their first release.\n",
    "- Crime - Crime rate: number of offenses per 100,000 population in 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of main modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import total_ordering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "# In this case read_csv method was used to read .txt file.\n",
    "# This method is very powerful to deal with as many problems as we can imagine!\n",
    "# Parameter sep was set to tab ('\\t')\n",
    "uscrime_df = pd.read_csv('./dataset/uscrime.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de dados\n",
    "\n",
    "Em um primeiro momento serão utilizados os métodos `.head()`, `.info()` e `.describe()`.\n",
    "\n",
    "- .head() -> Traz algumas entradas do dataset original, recebe como parâmetro o número de linhas que deseja-se visualizar, por default `n=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.108</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3940</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>26.2011</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.583</td>\n",
       "      <td>101.2</td>\n",
       "      <td>13</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.096</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5570</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>25.2999</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.533</td>\n",
       "      <td>96.9</td>\n",
       "      <td>18</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3180</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>24.3006</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.577</td>\n",
       "      <td>99.4</td>\n",
       "      <td>157</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6730</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>29.9012</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.591</td>\n",
       "      <td>98.5</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5780</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>21.2998</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M  So    Ed   Po1   Po2     LF    M.F  Pop    NW     U1   U2  Wealth  \\\n",
       "0  15.1   1   9.1   5.8   5.6  0.510   95.0   33  30.1  0.108  4.1    3940   \n",
       "1  14.3   0  11.3  10.3   9.5  0.583  101.2   13  10.2  0.096  3.6    5570   \n",
       "2  14.2   1   8.9   4.5   4.4  0.533   96.9   18  21.9  0.094  3.3    3180   \n",
       "3  13.6   0  12.1  14.9  14.1  0.577   99.4  157   8.0  0.102  3.9    6730   \n",
       "4  14.1   0  12.1  10.9  10.1  0.591   98.5   18   3.0  0.091  2.0    5780   \n",
       "\n",
       "   Ineq      Prob     Time  Crime  \n",
       "0  26.1  0.084602  26.2011    791  \n",
       "1  19.4  0.029599  25.2999   1635  \n",
       "2  25.0  0.083401  24.3006    578  \n",
       "3  16.7  0.015801  29.9012   1969  \n",
       "4  17.4  0.041399  21.2998   1234  "
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscrime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .info() -> retorna informações importantes sobre o dataset, como o número de entradas, estimativa de dados faltantes em cada coluna, o tipo de cada coluna e a memória utilizada para alocação do dataframe.\n",
    "\n",
    "Obs: Por padrão, as features numéricas em pandas alocam 32 ou 64 bits (`float64` ou `float32` e `int64` ou `int32`), é interessante, no caso de se trabalhar com conjuntos de dados mais volumosos e que não necessitam deste espaço na memória, que se altere os tipos das variáveis para `float16` e `int8`. Esta alteração é capaz de salvar um enorme espaço na memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   M       47 non-null     float64\n",
      " 1   So      47 non-null     int64  \n",
      " 2   Ed      47 non-null     float64\n",
      " 3   Po1     47 non-null     float64\n",
      " 4   Po2     47 non-null     float64\n",
      " 5   LF      47 non-null     float64\n",
      " 6   M.F     47 non-null     float64\n",
      " 7   Pop     47 non-null     int64  \n",
      " 8   NW      47 non-null     float64\n",
      " 9   U1      47 non-null     float64\n",
      " 10  U2      47 non-null     float64\n",
      " 11  Wealth  47 non-null     int64  \n",
      " 12  Ineq    47 non-null     float64\n",
      " 13  Prob    47 non-null     float64\n",
      " 14  Time    47 non-null     float64\n",
      " 15  Crime   47 non-null     int64  \n",
      "dtypes: float64(12), int64(4)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "uscrime_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .describe() -> Cálculo de diversas estatísticas relevantes para as variáveis numéricas como média, mediana, valores mínimos e máximos entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.857</td>\n",
       "      <td>0.340</td>\n",
       "      <td>10.564</td>\n",
       "      <td>8.500</td>\n",
       "      <td>8.023</td>\n",
       "      <td>0.561</td>\n",
       "      <td>98.302</td>\n",
       "      <td>36.617</td>\n",
       "      <td>10.113</td>\n",
       "      <td>0.095</td>\n",
       "      <td>3.398</td>\n",
       "      <td>5253.830</td>\n",
       "      <td>19.40</td>\n",
       "      <td>0.047</td>\n",
       "      <td>26.598</td>\n",
       "      <td>905.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.257</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.119</td>\n",
       "      <td>2.972</td>\n",
       "      <td>2.796</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2.947</td>\n",
       "      <td>38.071</td>\n",
       "      <td>10.283</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.845</td>\n",
       "      <td>964.909</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.023</td>\n",
       "      <td>7.087</td>\n",
       "      <td>386.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.700</td>\n",
       "      <td>4.500</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0.480</td>\n",
       "      <td>93.400</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.070</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2880.000</td>\n",
       "      <td>12.60</td>\n",
       "      <td>0.007</td>\n",
       "      <td>12.200</td>\n",
       "      <td>342.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.750</td>\n",
       "      <td>6.250</td>\n",
       "      <td>5.850</td>\n",
       "      <td>0.530</td>\n",
       "      <td>96.450</td>\n",
       "      <td>10.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>0.080</td>\n",
       "      <td>2.750</td>\n",
       "      <td>4595.000</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0.033</td>\n",
       "      <td>21.600</td>\n",
       "      <td>658.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.800</td>\n",
       "      <td>7.800</td>\n",
       "      <td>7.300</td>\n",
       "      <td>0.560</td>\n",
       "      <td>97.700</td>\n",
       "      <td>25.000</td>\n",
       "      <td>7.600</td>\n",
       "      <td>0.092</td>\n",
       "      <td>3.400</td>\n",
       "      <td>5370.000</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0.042</td>\n",
       "      <td>25.801</td>\n",
       "      <td>831.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>11.450</td>\n",
       "      <td>10.450</td>\n",
       "      <td>9.700</td>\n",
       "      <td>0.593</td>\n",
       "      <td>99.200</td>\n",
       "      <td>41.500</td>\n",
       "      <td>13.250</td>\n",
       "      <td>0.104</td>\n",
       "      <td>3.850</td>\n",
       "      <td>5915.000</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.054</td>\n",
       "      <td>30.451</td>\n",
       "      <td>1057.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.700</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12.200</td>\n",
       "      <td>16.600</td>\n",
       "      <td>15.700</td>\n",
       "      <td>0.641</td>\n",
       "      <td>107.100</td>\n",
       "      <td>168.000</td>\n",
       "      <td>42.300</td>\n",
       "      <td>0.142</td>\n",
       "      <td>5.800</td>\n",
       "      <td>6890.000</td>\n",
       "      <td>27.60</td>\n",
       "      <td>0.120</td>\n",
       "      <td>44.000</td>\n",
       "      <td>1993.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M      So      Ed     Po1     Po2      LF      M.F      Pop  \\\n",
       "count  47.000  47.000  47.000  47.000  47.000  47.000   47.000   47.000   \n",
       "mean   13.857   0.340  10.564   8.500   8.023   0.561   98.302   36.617   \n",
       "std     1.257   0.479   1.119   2.972   2.796   0.040    2.947   38.071   \n",
       "min    11.900   0.000   8.700   4.500   4.100   0.480   93.400    3.000   \n",
       "25%    13.000   0.000   9.750   6.250   5.850   0.530   96.450   10.000   \n",
       "50%    13.600   0.000  10.800   7.800   7.300   0.560   97.700   25.000   \n",
       "75%    14.600   1.000  11.450  10.450   9.700   0.593   99.200   41.500   \n",
       "max    17.700   1.000  12.200  16.600  15.700   0.641  107.100  168.000   \n",
       "\n",
       "           NW      U1      U2    Wealth   Ineq    Prob    Time     Crime  \n",
       "count  47.000  47.000  47.000    47.000  47.00  47.000  47.000    47.000  \n",
       "mean   10.113   0.095   3.398  5253.830  19.40   0.047  26.598   905.085  \n",
       "std    10.283   0.018   0.845   964.909   3.99   0.023   7.087   386.763  \n",
       "min     0.200   0.070   2.000  2880.000  12.60   0.007  12.200   342.000  \n",
       "25%     2.400   0.080   2.750  4595.000  16.55   0.033  21.600   658.500  \n",
       "50%     7.600   0.092   3.400  5370.000  17.60   0.042  25.801   831.000  \n",
       "75%    13.250   0.104   3.850  5915.000  22.75   0.054  30.451  1057.500  \n",
       "max    42.300   0.142   5.800  6890.000  27.60   0.120  44.000  1993.000  "
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizei arredondamento para facilitar a visualização dos dados lembrando que como pandas é baseado em numpy as operações\n",
    "# são facilmente aplicáveis a todos os valores do dataframe.\n",
    "round(uscrime_df.describe(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inconsistências nos tipos de variáveis\n",
    "\n",
    "Observando a descrição das variáveis, suas estruturas de dados e os valores das estatísticas, observa-se que temos uma inconsistencia com a feature `So`. Esta é uma feature categórica, que indica se a entrada é ou não de um estado do sul, logo cálculos como média, desvio padrão e quartis não fazem muito sentido. Neste caso, é necessário fazer uma alteração no tipo da variável para categórica e aplicar novamente o método .describe(). Será possível observar uma adaptação do pandas para tratar este tipo de dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>So</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        So\n",
       "count   47\n",
       "unique   2\n",
       "top      0\n",
       "freq    31"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method .astype() to transform data type to category\n",
    "uscrime_df[['So']].astype('category').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterando-se o tipo do dado para categórico observa-se a alteração nas estatisticas cálculadas pelo método `.describe()`, agora posso analisar quantos valores únicos a variável possui (no caso, 0 e 1), qual o valor mais frequente (top = 0) e sua frequência (31 ocorrências em 47 aproximadamente 65,96%).  \n",
    "Como observado, há apenas duas categorias para esta variável, com isso manterei esta coluna como tipo inteiro, já que esta poderá ser utilizada como feature no desenvolvimento do modelo preditivo.  \n",
    "Em casos onde ocorrem mais opções de categorias, podemos utilizar metodologias como `one hot encoding` ou `get_dummies` para transformar estas features em features numéricas, onde seriam criadas novas colunas no data frame, cada uma representando uma categoria (lembrando-se de criar n-1 novas colunas para que não aja uma redundância que prejudique o desempenho do modelo). A ideia desta metodologia é que ao criar categorias numéricas, os modelos de predição não considerem números mais altos como mais importantes e com a criação de uma coluna para cada categoria, garanto que os valores possíveis sejam somente 1 (caso pertença a categoria) e 0 (caso não pertença)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de Dados Faltantes\n",
    "\n",
    "Esta é uma etapa importantíssima da análise exploratória de dados, neste caso não há ocorrencia de dados faltantes mas caso houvesse teriamos que pensar em uma estratégia para tratá-los. Seguem algumas possibilidades:\n",
    "\n",
    "- Caso seja uma quantidade pouco significativa com relação ao volume total de dados, posso simplesmente deletar as entradas com dados faltantes (lembrando que a definição do que seria 'pouco significativo' varia de caso pra caso).\n",
    "- Podemos utilizar estatísticas para preenchimento, como média, mediana, valores mínimos e máximos.\n",
    "- Podemos utilizar uma regra de negócio para preenchimento.\n",
    "- Podemos nos basear em outras variáveis para obtenção desses valores, tanto através de relações diretas quanto através de modelos preditivos.\n",
    "\n",
    "Enfim, provavelmente existem outras formas de analisar e fazer o preenchimento de dados faltantes sendo esta uma análise peculiar de cada conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value? -> No\n"
     ]
    }
   ],
   "source": [
    "# Como uma análise rápida da presença ou não de dados faltantes posso rodar a seguinte linha de código:\n",
    "\n",
    "has_nan = any(uscrime_df.isna().sum())\n",
    "print(f\"Is there any missing value? -> {'Yes' if has_nan else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de correlação entre variáveis\n",
    "\n",
    "Uma forma e efetiva de observar como as variáveis se relacionam, é análisar a correlação entre elas. O pandas já tem um método nativo .corr() que quando aplicado ao data frame, retorna como as variáveis numéricas se relacionam umas com as outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.584</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So</th>\n",
       "      <td>0.584</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ed</th>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Po1</th>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.483</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.526</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Po2</th>\n",
       "      <td>-0.513</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.794</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF</th>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.106</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M.F</th>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.514</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NW</th>\n",
       "      <td>0.593</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.095</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1</th>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U2</th>\n",
       "      <td>-0.245</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wealth</th>\n",
       "      <td>-0.670</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.092</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ineq</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.677</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M     So     Ed    Po1    Po2     LF    M.F    Pop     NW     U1  \\\n",
       "M       1.000  0.584 -0.530 -0.506 -0.513 -0.161 -0.029 -0.281  0.593 -0.224   \n",
       "So      0.584  1.000 -0.703 -0.373 -0.376 -0.505 -0.315 -0.050  0.767 -0.172   \n",
       "Ed     -0.530 -0.703  1.000  0.483  0.499  0.561  0.437 -0.017 -0.665  0.018   \n",
       "Po1    -0.506 -0.373  0.483  1.000  0.994  0.121  0.034  0.526 -0.214 -0.044   \n",
       "Po2    -0.513 -0.376  0.499  0.994  1.000  0.106  0.023  0.514 -0.219 -0.052   \n",
       "LF     -0.161 -0.505  0.561  0.121  0.106  1.000  0.514 -0.124 -0.341 -0.229   \n",
       "M.F    -0.029 -0.315  0.437  0.034  0.023  0.514  1.000 -0.411 -0.327  0.352   \n",
       "Pop    -0.281 -0.050 -0.017  0.526  0.514 -0.124 -0.411  1.000  0.095 -0.038   \n",
       "NW      0.593  0.767 -0.665 -0.214 -0.219 -0.341 -0.327  0.095  1.000 -0.156   \n",
       "U1     -0.224 -0.172  0.018 -0.044 -0.052 -0.229  0.352 -0.038 -0.156  1.000   \n",
       "U2     -0.245  0.072 -0.216  0.185  0.169 -0.421 -0.019  0.270  0.081  0.746   \n",
       "Wealth -0.670 -0.637  0.736  0.787  0.794  0.295  0.180  0.308 -0.590  0.045   \n",
       "Ineq    0.639  0.737 -0.769 -0.631 -0.648 -0.270 -0.167 -0.126  0.677 -0.064   \n",
       "Prob    0.361  0.531 -0.390 -0.473 -0.473 -0.250 -0.051 -0.347  0.428 -0.007   \n",
       "Time    0.115  0.067 -0.254  0.103  0.076 -0.124 -0.428  0.464  0.230 -0.170   \n",
       "Crime  -0.089 -0.091  0.323  0.688  0.667  0.189  0.214  0.337  0.033 -0.050   \n",
       "\n",
       "           U2  Wealth   Ineq   Prob   Time  Crime  \n",
       "M      -0.245  -0.670  0.639  0.361  0.115 -0.089  \n",
       "So      0.072  -0.637  0.737  0.531  0.067 -0.091  \n",
       "Ed     -0.216   0.736 -0.769 -0.390 -0.254  0.323  \n",
       "Po1     0.185   0.787 -0.631 -0.473  0.103  0.688  \n",
       "Po2     0.169   0.794 -0.648 -0.473  0.076  0.667  \n",
       "LF     -0.421   0.295 -0.270 -0.250 -0.124  0.189  \n",
       "M.F    -0.019   0.180 -0.167 -0.051 -0.428  0.214  \n",
       "Pop     0.270   0.308 -0.126 -0.347  0.464  0.337  \n",
       "NW      0.081  -0.590  0.677  0.428  0.230  0.033  \n",
       "U1      0.746   0.045 -0.064 -0.007 -0.170 -0.050  \n",
       "U2      1.000   0.092  0.016 -0.062  0.101  0.177  \n",
       "Wealth  0.092   1.000 -0.884 -0.555  0.001  0.441  \n",
       "Ineq    0.016  -0.884  1.000  0.465  0.102 -0.179  \n",
       "Prob   -0.062  -0.555  0.465  1.000 -0.436 -0.427  \n",
       "Time    0.101   0.001  0.102 -0.436  1.000  0.150  \n",
       "Crime   0.177   0.441 -0.179 -0.427  0.150  1.000  "
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neste caso, criei um novo data frame para receber a correlação entre variáveis\n",
    "uscrime_correlation_df = round(uscrime_df.corr(), 3)\n",
    "uscrime_correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Geração do mapa de calor para as correlações entre variáveis numéricas do data frame.\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(uscrime_correlation_df, center=0, cmap='seismic');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M        -0.089\n",
       "So       -0.091\n",
       "Ed        0.323\n",
       "Po1       0.688\n",
       "Po2       0.667\n",
       "LF        0.189\n",
       "M.F       0.214\n",
       "Pop       0.337\n",
       "NW        0.033\n",
       "U1       -0.050\n",
       "U2        0.177\n",
       "Wealth    0.441\n",
       "Ineq     -0.179\n",
       "Prob     -0.427\n",
       "Time      0.150\n",
       "Name: Crime, dtype: float64"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_with_crime = uscrime_correlation_df.loc['Crime'][uscrime_correlation_df.columns != 'Crime']\n",
    "correlation_with_crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observações importantes:\n",
    "\n",
    "Considerando as correlações e mapa de calor, observa-se que as variáveis `Po1` e `Po2` são as que apresentam maiores correlações com a variável alvo (respectivamente 0.688 e 0.667), observa-se também que estas variáveis apresentam correlação de quase 1 entre elas (0.994), isto significa que posso utilizar somente uma delas em meu modelo preditivo reduzindo assim a dimensão do problema. Neste caso irei utilizar a variável `Po1`que apresenta maior correlação com a variável alvo.\n",
    "As variáveis `M`, `So`, `NW` e  `U1` apresentam correlações menores que 0.1 e -0.1 logo não serão consideradas no desenvolvimento do modelo preditivo.\n",
    "Nesta etapa, vou utilizar do desenvolvimento orientado a objetos para desenvolvimento do modelo preditivo, a ideia é que com esta modelagem, seja possível criar e comparar modelos, com objetivo de se obter o melhor modelo possível considerando os critérios adotados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvimento da classe CrimeRatePredictor\n",
    "\n",
    "Esta classe será utilizada para abstrair todas as etapas do desenvolvimento do modelo de predição, a ideia é fazer um desenvolvimento focado na reusabilidade, escalabilidade e manutenção. Fazendo também uma boa definição de cada método, é possível executar testes unitários de maneira bem simples e direta.\n",
    "\n",
    "Vou comentar um pouco sobre os métodos mais importantes desta classe:\n",
    "\n",
    "- `feature_selection()` - Este método, define quais features serão utilizadas no modelo preditivo. Em um primeiro momento, utilizei a análise de correlações, tendo como parâmetro um fator de corte.\n",
    "\n",
    "- `transform_data_with_selected_features()` - Este método aplica as features selecionadas no data frame, obtendo o data frame específico que será utilizado no modelo preditivo. Há também um método estático que será utilizado para transformar novos dados.\n",
    "\n",
    "- `split_data_into_train_test_part()` - Método utilizado para particionar os dados originais em dados de treino e dados de teste com isso poderei validar o modelo calculando métricas que possam ser comparaveis.\n",
    "\n",
    "- `fit_model_to_predict()` - Método responsável por calibrar o modelo. Em um primeiro momento utilizei regressão linear.\n",
    "\n",
    "- `make_predictions_with_test_data()` - Método responsável por calcular predizer resultado utilizando os dados de teste com objetivo de serem utilizados no calculo das métricas de validação.\n",
    "\n",
    "- `calculate_model_metric()` - Esta função calcula a métrica de avaliação dos modelos utilizando as predições dos dados de teste. A métrica calculada é alocada em um atributo, este atributo será utilizado nos métodos de ordenação, permitindo que objetos da classe possam ser ordenados quando dispostos em uma coleção.\n",
    "\n",
    "- `@total_ordering`, `__eq__()` e `__lt__()` - Definem métodos que permitem que objetos desta classe sejam ordenáveis de acordo com algum critério espefico. Neste caso vou utilizar a métrica.\n",
    "\n",
    "\n",
    "# Métrica utilizada: explained_variance_score:\n",
    "\n",
    "Esta métrica, explica a dispersão dos erros de um determinado conjunto de dados. Quanto mais próximo de 1, melhor o modelo, indicando melhores quadrados do desvios padrão dos erros.\n",
    "\n",
    "[referencia 1:](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)  \n",
    "[referencia 2:](https://books.google.com.br/books?id=7S6WDwAAQBAJ&pg=PA332&lpg=PA332&dq=explained_variance_score&source=bl&ots=awF03vf-ai&sig=ACfU3U0TjsTsxfY6KxJfUFuHEUGpR3IM4w&hl=pt-BR&sa=X&ved=2ahUKEwiS2M3TqK_qAhXmGbkGHaNAB4oQ6AEwDnoECAoQAQ#v=onepage&q=explained_variance_score&f=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "@total_ordering\n",
    "class CrimeRatePredictor(object):\n",
    "    \"\"\"\n",
    "    This class will be used as a model for specific child classes for each considered predictive model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, crime_df):\n",
    "        \n",
    "        # This class will delete 'Po2' from original data frame once we decided didn't consider it in our analysis.\n",
    "        self.crime_df = crime_df.copy()\n",
    "        del (self.crime_df['Po2'])\n",
    "        \n",
    "        # List of features that will be used according some criteria\n",
    "        self.corr_factor = 0\n",
    "        self.features_to_use = []\n",
    "        \n",
    "        # Target name in case of use it in other methods\n",
    "        self.target_name = 'Crime'\n",
    "        \n",
    "        # Complete data from target variable\n",
    "        self.target_data = self.crime_df[self.target_name]\n",
    "        \n",
    "        # Attribute to allocate complete data \n",
    "        self.complete_x_data = self.crime_df.drop(columns='Crime')\n",
    "        \n",
    "        # Attributes that will be used into train x test split\n",
    "        self.x_train = 'This attribute is not defined yet'\n",
    "        self.x_test = 'This attribute is not defined yet'\n",
    "        self.y_train = 'This attribute is not defined yet'\n",
    "        self.y_test = 'This attribute is not defined yet'\n",
    "        \n",
    "        # Number that ensures that the numerical experiment can be reproduced.\n",
    "        self.random_seed = 42\n",
    "        \n",
    "        # Infos about prediction model.\n",
    "        self.model_name = 'Linear Regression'\n",
    "        self.model = LinearRegression()\n",
    "        self.model_metric = 'This attribute is not defined yet'\n",
    "        \n",
    "        # Values predicted using x_test to validate the model.\n",
    "        self.y_test_pred = 'This attribute is not defined yet'\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def model_info(self):\n",
    "        \n",
    "        complete_info =  f\"Model: {self.model_name} \"\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Correlation Factor: {self.corr_factor} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Number of features used: {len(self.features_to_use)} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Metric - Explained Variance Score: {round(self.model_metric, 3)}'\n",
    "        return complete_info\n",
    "    \n",
    "    @property\n",
    "    def print_shape(self):\n",
    "        \"\"\"\n",
    "        Method to print the number of rows and columns.\n",
    "        \"\"\"\n",
    "        print(f'Number of lines: {self.crime_df.shape[0]}')\n",
    "        print(f'Number of columns: {self.crime_df.shape[1]}')\n",
    "        \n",
    "    @property\n",
    "    def print_column_names(self):\n",
    "        \"\"\"\n",
    "        Method to print column names of the original data frame.\n",
    "        \"\"\"\n",
    "        print('Column names:')\n",
    "        \n",
    "        for column in self.crime_df.columns:\n",
    "            \n",
    "            print(f'             {column} - type: {self.crime_df[column].dtype}')\n",
    "        \n",
    "    def show_dataframe_information(self):\n",
    "        \"\"\"\n",
    "        Show information about data frame used to develop this model.\n",
    "        \"\"\"\n",
    "        print('========= Start Data Frame Information ==========')\n",
    "        print('\\n')\n",
    "        self.print_shape\n",
    "        self.print_column_names\n",
    "        print('\\n')\n",
    "        print('========= Finish Data Frame Information ==========')\n",
    "        \n",
    "   \n",
    "    def feature_selection(self, corr_factor: float) -> list:\n",
    "        \"\"\"\n",
    "        Method based on a correlation factor to decide which features will be used to implement a predictive model.\n",
    "        \n",
    "        args:\n",
    "        \n",
    "            corr_factor: float -> factor that will be used to select most influent features. In this case, features that\n",
    "                                  presents correlation with target greater than corr_factor or less than (-corr_factor).\n",
    "                                  \n",
    "        return: \n",
    "            \n",
    "            self.features_to_use: list -> List of features that will be used defined by corr_factor criteria.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.corr_factor = corr_factor\n",
    "        # Create the correlational data frame.\n",
    "        crime_df_corr = self.crime_df.corr()\n",
    "        \n",
    "        # Obtain the conditional to filter the correlation data frame considering the corr_factor\n",
    "        evaluate_corr_factor_conditional = (crime_df_corr[self.target_name] >= corr_factor) \\\n",
    "                                           | (crime_df_corr[self.target_name] <= -corr_factor)\n",
    "        \n",
    "        # Select all features that achieve the corr_factor test.\n",
    "        self.features_to_use = crime_df_corr[evaluate_corr_factor_conditional].index\n",
    "        \n",
    "        # Drop target column (Crime) and transform to list.\n",
    "        self.features_to_use = self.features_to_use.drop(self.target_name).tolist()\n",
    "        \n",
    "        return self.features_to_use\n",
    "        \n",
    "    def transform_data_with_selected_features(self):\n",
    "        \"\"\"\n",
    "        This method get data just using the selected features\n",
    "        \n",
    "        return:\n",
    "            \n",
    "            self.complete_x_data: pd.DataFrame -> Data Frame containing just selected features\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x_train = self.x_train[self.features_to_use]\n",
    "        self.x_test = self.x_test[self.features_to_use]\n",
    "        print('x_train and x_test were transformed using feature selection.')\n",
    "        \n",
    "        \n",
    "    def split_data_into_train_test_part(self, split_factor=0.3) -> str:\n",
    "        \"\"\"\n",
    "        Method used to divide complete data into train/test data to use to fit and validate the predictive model.\n",
    "        \n",
    "        args:\n",
    "            \n",
    "            split_factor: float -> Value that deifne the partition between train and test. This factor refers to test quantity.\n",
    "                          So, if split_factor equals 0.3 means that 30% of data will be used to test.\n",
    "                          \n",
    "        return:\n",
    "        \n",
    "            message: str -> Message that means everything works well, it's recomended that if an user wants to see and explore\n",
    "                     train and test data, just access it by object attributes.\n",
    "        \"\"\"\n",
    "        \n",
    "        message = 'Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.'\n",
    "        \n",
    "        splitted_results = train_test_split(self.complete_x_data, self.target_data, random_state=self.random_seed\\\n",
    "                                            , test_size=split_factor)\n",
    "        \n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = splitted_results\n",
    "        \n",
    "        print(message)\n",
    "    \n",
    "    def fit_model_to_predict(self):\n",
    "        \"\"\"\n",
    "        Method do calibrate the prediction model using x_train\n",
    "        \"\"\"\n",
    "        self.model.fit(self.x_train, self.y_train)\n",
    "        print(f'The {self.model_name} was fitted and is ready to use!')\n",
    "        \n",
    "    def make_predictions_with_test_data(self):\n",
    "        \"\"\"\n",
    "        Method to predict results using x_test data in order to validade the model and server as input into metrics \n",
    "        calculations.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.y_test_pred = self.model.predict(self.x_test)\n",
    "        print(f'Results were predicted using x_test data in order to validade the model.')\n",
    "        \n",
    "    def calculate_model_metric(self):\n",
    "        \"\"\"\n",
    "        Method to calculate the performance of the model that will be used to compare with others and make it orderable when\n",
    "        within a collection.\n",
    "        \"\"\"\n",
    "        self.model_metric = explained_variance_score(self.y_test, self.y_test_pred)\n",
    "        return self.model_metric\n",
    "    \n",
    "\n",
    "    def tranform_external_data_with_selected_features(self, external_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform external data using the selected features\n",
    "        \n",
    "        args:\n",
    "        \n",
    "            external_data: pd.DataFrame -> New data to transform using the selected features.\n",
    "            \n",
    "        return:\n",
    "        \n",
    "            Modified data frame considering just selected features.\n",
    "        \n",
    "        \"\"\"\n",
    "        return external_data[self.features_to_use]\n",
    "    \n",
    "\n",
    "    def make_predictions_with_external_data(self, external_data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions using external data, remember that before this step, apply the method transform_external_data_with_\n",
    "        selected_features.\n",
    "        args:\n",
    "        \n",
    "            external_data: pd.DataFrame -> External, transformed data frame.\n",
    "            \n",
    "        return:\n",
    "        \n",
    "            numpy array with predictions for one or more entries.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.model.predict(external_data)\n",
    "\n",
    "    # dunder methods to make object orderable into collections.\n",
    "    def __eq__(self, other):\n",
    "        \n",
    "        return self.model_metric == other.model_metric\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        \n",
    "        return self.model_metric < other.model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste ponto, tenho uma classe capaz de criar objetos que representam um modelo de predição para os dados presentes e, uscrime.txt. Aproveitando a reusabilidade do código posso facilmente criar diferentes modelos variando o valor de corte para a correlação, ordenando-os em uma lista obtendo assim o modelo com melhor métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_crime_model(corr: float) -> CrimeRatePredictor:\n",
    "    \n",
    "    print(f\"Creating an object with correlation factor = {corr}\")\n",
    "    \n",
    "    # Pipeline to create a PredictCrimeModel\n",
    "    \n",
    "    # Create the object with uscrime data frame\n",
    "    PredictCrimeModel = CrimeRatePredictor(uscrime_df)\n",
    "    \n",
    "    # Split data into train and test data with 0.3 (30% rate)\n",
    "    PredictCrimeModel.split_data_into_train_test_part(0.3)\n",
    "    \n",
    "    # Select features considering the correlation value\n",
    "    PredictCrimeModel.feature_selection(corr)\n",
    "    \n",
    "    # Tranform data using selected features\n",
    "    PredictCrimeModel.transform_data_with_selected_features()\n",
    "    \n",
    "    # Fit the model using train data\n",
    "    PredictCrimeModel.fit_model_to_predict()\n",
    "    \n",
    "    # Make predictions with test data\n",
    "    PredictCrimeModel.make_predictions_with_test_data()\n",
    "    \n",
    "    # Calculate the metric based on Explained variance score\n",
    "    PredictCrimeModel.calculate_model_metric()\n",
    "    print(PredictCrimeModel.model_info)\n",
    "    print('\\n')\n",
    "    \n",
    "    return PredictCrimeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating an object with correlation factor = 0\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0 -> Number of features used: 14 -> Metric - Explained Variance Score: 0.779\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.1\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.1 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.716\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.2\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.2 -> Number of features used: 6 -> Metric - Explained Variance Score: 0.623\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.3\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.3 -> Number of features used: 5 -> Metric - Explained Variance Score: 0.6\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.4\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.4 -> Number of features used: 3 -> Metric - Explained Variance Score: 0.606\n",
      "\n",
      "\n",
      "Best model information: \n",
      "Model: Linear Regression -> Correlation Factor: 0 -> Number of features used: 14 -> Metric - Explained Variance Score: 0.779\n"
     ]
    }
   ],
   "source": [
    "# In this step I'll create differente models using different\n",
    "\n",
    "correlations = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "\n",
    "# Create a list of CrimeRatePredictor objects:\n",
    "\n",
    "crime_predictors = [create_prediction_crime_model(corr) for corr in correlations]\n",
    "\n",
    "crime_predictors = sorted(crime_predictors)\n",
    "\n",
    "best_model_corr = crime_predictors[-1]\n",
    "\n",
    "print('Best model information: ')\n",
    "print(best_model_corr.model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo em produção\n",
    "\n",
    "Neste ponto, conseguimos avaliar diferentes modelos considerando diferentes conjuntos de features.  \n",
    "Através do paradigma de orientação a objetos, conseguimos facilmente gerar os objetos que armazenam o modelo e ordena-los de acordo com a métrica, obtendo assim o melhor modelo com as premissas consideradas.\n",
    "O melhor modelo utiliza todas as features e obtém um score de 0.78/1 considerando a métrica `explained variance score`. É possível entregar uma solução para um possível cliente agora, gerando valor e dando a tranquilidade para continuar trabalhando na melhoria do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando o modelo para fazer novas predições\n",
    "\n",
    "Vamos utilizar o melhor modelo até então, para calcular a taxa de criminalidade com o ponto adicional fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.64</td>\n",
       "      <td>94.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3200</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M  So    Ed   Po1   Po2    LF   M.F  Pop   NW    U1   U2  Wealth  Ineq  \\\n",
       "0  14.0   0  10.0  12.0  15.5  0.64  94.0  150  1.1  0.12  3.6    3200  20.1   \n",
       "\n",
       "   Prob  Time  \n",
       "0  0.04  39.0  "
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_calculate = {'M':[14.0],\n",
    "                     'So': [0],\n",
    "                     'Ed': [10.0],\n",
    "                     'Po1': [12.0],\n",
    "                     'Po2': [15.5],\n",
    "                     'LF': [0.640],\n",
    "                     'M.F': [94.0],\n",
    "                     'Pop': [150],\n",
    "                     'NW': [1.1],\n",
    "                     'U1': [0.120],\n",
    "                     'U2': [3.6],\n",
    "                     'Wealth': [3200],\n",
    "                     'Ineq': [20.1],\n",
    "                     'Prob': [0.04],\n",
    "                     'Time': [39.0]}\n",
    "\n",
    "data_df = pd.DataFrame(data_to_calculate)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor predito para os novos dados é 1024.44\n"
     ]
    }
   ],
   "source": [
    "transformed_data = best_model_corr.tranform_external_data_with_selected_features(data_df)\n",
    "predict_value_corr = best_model_corr.make_predictions_with_external_data(transformed_data)\n",
    "\n",
    "\n",
    "print(f'O valor predito para os novos dados é {round(predict_value_corr[0], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herança e Polimorfismo\n",
    "\n",
    "Da forma como o modelo foi contruido, podemos facilmente adicionar e alterar funcionalidades, corrigir possíveis erros sem afetar o todo e trabalhar bem em equipe onde cada membro do time pode focar em desenvolver ou melhorar uma funcionalidade especifica. Um conceito muito interessante e que pode ser aplicado em um desenvolvimento orientado a objetos, é a herança e polimorfismo. Podemos construir uma classe que herda as características (atributos e métodos) da classe atual, alterando apenas a funcionalidade de interesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecionando features com o RFE\n",
    "\n",
    "RFE é um modelo presente no módulo scikit learn e é utilizado para definir quais variáveis impactam mais no modelo preditivo. As variáveis vão sendo eliminadas uma a uma até chegar no vlaor estipulado. Neste caso, vou redefinir o método de seleção de features da classe CrimeRatePredictor e fazer a seleção eliminando de 1 a 5 variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrimeRatePredictorUsingRFE(CrimeRatePredictor):\n",
    "    \n",
    "    def __init__(self, crime_df):\n",
    "        \n",
    "        super().__init__(crime_df)\n",
    "        self.n_features_to_remove = None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def model_info(self):\n",
    "        \n",
    "        complete_info =  f\"Model: {self.model_name} \"\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Number of features to remove: {self.n_features_to_remove} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Number of features used: {len(self.features_to_use)} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Metric - Explained Variance Score: {round(self.model_metric, 3)}'\n",
    "        return complete_info\n",
    "    \n",
    "    def feature_selection(self, n_removed_features=None) -> list:\n",
    "        \"\"\"\n",
    "        Method based on a RFE model to decide which features will be used to implement a predictive model.\n",
    "        \n",
    "        args:\n",
    "        \n",
    "            n_removed_features: int -> Define the number of features that will be eliminated.\n",
    "                                  \n",
    "        return: \n",
    "            \n",
    "            self.features_to_use: list -> List of features that will be used defined by corr_factor criteria.\n",
    "        \"\"\"\n",
    "        self.n_features_to_remove = n_removed_features\n",
    "        \n",
    "        # Define RFE model using Linear Regression to calculate.\n",
    "        # n_removed_features define the number of features that will be eliminated.\n",
    "        rfe = RFE(self.model, n_features_to_select=len(self.x_train.columns) - n_removed_features)\n",
    "            \n",
    "        # Fit RFE model using x_train and y_train\n",
    "        rfe.fit(self.x_train, self.y_train)\n",
    "            \n",
    "        # Get info from RFE\n",
    "        rfe_info =  pd.DataFrame({'column': self.x_train.columns,\n",
    "                                      'bool': rfe.get_support()})\n",
    "        only_true_rfe = rfe_info[rfe_info['bool'] == True]\n",
    "        self.features_to_use = only_true_rfe['column'].tolist()\n",
    "            \n",
    "        \n",
    "        return self.features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_crime_model_rfe(n_features: float) -> CrimeRatePredictorUsingRFE:\n",
    "    \n",
    "    print(f\"Creating an object with n number of removed features = {n_features}\")\n",
    "    \n",
    "    # Pipeline to create a PredictCrimeModel\n",
    "    \n",
    "    # Create the object with uscrime data frame\n",
    "    PredictCrimeModel = CrimeRatePredictorUsingRFE(uscrime_df)\n",
    "    \n",
    "    # Split data into train and test data with 0.3 (30% rate)\n",
    "    PredictCrimeModel.split_data_into_train_test_part(0.3)\n",
    "    \n",
    "    # Select features considering the correlation value\n",
    "    PredictCrimeModel.feature_selection(n_features)\n",
    "    \n",
    "    # Tranform data using selected features\n",
    "    PredictCrimeModel.transform_data_with_selected_features()\n",
    "    \n",
    "    # Fit the model using train data\n",
    "    PredictCrimeModel.fit_model_to_predict()\n",
    "    \n",
    "    # Make predictions with test data\n",
    "    PredictCrimeModel.make_predictions_with_test_data()\n",
    "    \n",
    "    # Calculate the metric based on Explained variance score\n",
    "    PredictCrimeModel.calculate_model_metric()\n",
    "    print(PredictCrimeModel.model_info)\n",
    "    print('\\n')\n",
    "    \n",
    "    return PredictCrimeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating an object with n number of removed features = 1\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 1 -> Number of features used: 13 -> Metric - Explained Variance Score: 0.766\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 2\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 2 -> Number of features used: 12 -> Metric - Explained Variance Score: 0.766\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 3\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 3 -> Number of features used: 11 -> Metric - Explained Variance Score: 0.818\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 4\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 4 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.818\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 5\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 5 -> Number of features used: 9 -> Metric - Explained Variance Score: 0.815\n",
      "\n",
      "\n",
      "Best model information: \n",
      "Model: Linear Regression -> Number of features to remove: 4 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.818\n"
     ]
    }
   ],
   "source": [
    "# In this step I'll create differente models using different number of features to remove.\n",
    "\n",
    "n_features_to_remove = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "# Create a list of CrimeRatePredictorUsingRFE objects:\n",
    "\n",
    "crime_predictors = [create_prediction_crime_model_rfe(n) for n in n_features_to_remove]\n",
    "\n",
    "crime_predictors = sorted(crime_predictors)\n",
    "\n",
    "best_model_rfe = crime_predictors[-2]\n",
    "\n",
    "print('Best model information: ')\n",
    "print(best_model_rfe.model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used in the best correlation model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M,So,Ed,Po1,LF,M.F,Pop,NW,U1,U2,Wealth,Ineq,Prob,Time'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used in the rfe model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M,Ed,Po1,LF,M.F,U1,U2,Ineq,Prob,Time'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation model - explained_variance_score: 0.779\n",
      "RFE model - explained_variance_score: 0.818\n"
     ]
    }
   ],
   "source": [
    "print('Features used in the best correlation model:')\n",
    "display(','.join(best_model_corr.features_to_use))\n",
    "\n",
    "print('Features used in the rfe model:')\n",
    "display(','.join(best_model_rfe.features_to_use))\n",
    "\n",
    "print(f'Correlation model - explained_variance_score: {round(best_model_corr.model_metric, 3)}')\n",
    "print(f'RFE model - explained_variance_score: {round(best_model_rfe.model_metric, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor resultado para o modelo que seleciona as features através das maiores correlações considerou todas as features para definição da regressão linear. Aplicando-se a seleção de features pelo RFE, observa-se que o melhor modelo eliminou 4 features, entre elas `Wealth` e `Pop` que embora apresentem correlações consideráveis com a variável alvo, prejudicam a regressão linear.  \n",
    "Com isso, além do ganho de desempenho de `0.779` para `0.818`, ainda obtive um modelo mais performático que executa os cálculos considerando 4 features a menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor predito para os novos dados é 1222.06\n"
     ]
    }
   ],
   "source": [
    "transformed_data = best_model_rfe.tranform_external_data_with_selected_features(data_df)\n",
    "predict_value_rfe = best_model_rfe.make_predictions_with_external_data(transformed_data)\n",
    "\n",
    "\n",
    "print(f'O valor predito para os novos dados é {round(predict_value_rfe[0], 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation model - Valor predito: 1024.44\n",
      "RFE model - Valor  predito: 1222.06\n"
     ]
    }
   ],
   "source": [
    "print(f'Correlation model - Valor predito: {round(predict_value_corr[0], 2)}')\n",
    "print(f'RFE model - Valor  predito: {round(predict_value_rfe[0], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este exemplo demonstrou o poder do paradigma da orientação a objetos aplicado a um projeto de ciência de dados, onde de forma simples é possível analisar cada parte do código em busca de melhor performance e melhor desempenho preditivo.  \n",
    "Outras análises que podem ser feitas:\n",
    "\n",
    "- Aplicação da redução de dimensionalidade utilizando PCA\n",
    "- Inclusão de outras métricas para análise do modelo como `Mean Square Error` ou `Median Absolut Error`. Lembrando que para fazer isto basta seguir os conceitos de herança e polimorfismo para criar outra classe variando apenas o método que cálcula essas métricas.\n",
    "- Análise de outros modelos de regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model Information: \n",
      "Model: Linear Regression -> Number of features to remove: 4 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.818\n"
     ]
    }
   ],
   "source": [
    "print('The best model Information: ')\n",
    "print(best_model_rfe.model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observação final:  \n",
    "\n",
    "Outro ponto importante desta forma de desenvolvimento é a possibilidade de execução de testes unitários para cada etapa do código, fazendo com que a qualidade seja garantida, minimizando retrabalho e erros futuros. Sendo assim, podemos avançar com a cabeça mais tranquila para as próximas etapas.\n",
    "\n",
    "Perguntas como:\n",
    "\n",
    "- Será que meu modelo seleciona as features corretamente?\n",
    "- Será que minha divisão entre dados de teste e treino esá sendo feita corretamente?\n",
    "\n",
    "Entre outras, podem ser feitas e respondidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n"
     ]
    }
   ],
   "source": [
    "# Pipeline to create a PredictCrimeModel\n",
    "    \n",
    "# Create the object with uscrime data frame\n",
    "PredictCrimeModel = CrimeRatePredictor(uscrime_df)\n",
    "    \n",
    "# Split data into train and test data with 0.3 (30% rate)\n",
    "PredictCrimeModel.split_data_into_train_test_part(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert PredictCrimeModel.feature_selection(0.4) == ['Po1', 'Wealth', 'Prob']\n",
    "assert round(len(PredictCrimeModel.x_train) / len(uscrime_df), 1) == 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert que não retorna nada passou no teste =D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of main modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import total_ordering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "# In this case read_csv method was used to read .txt file.\n",
    "# This method is very powerful to deal with as many problems as we can imagine!\n",
    "# Parameter sep was set to tab ('\\t')\n",
    "uscrime_df = pd.read_csv('./dataset/uscrime.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis\n",
    "\n",
    "At first, the `.head ()`, `.info ()` and `.describe ()` methods will be used.\n",
    "\n",
    "- .head () -> It brings some entries from the original dataset, it receives as parameter the number of lines that you want to view, by default `n = 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.108</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3940</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>26.2011</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.583</td>\n",
       "      <td>101.2</td>\n",
       "      <td>13</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.096</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5570</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>25.2999</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.533</td>\n",
       "      <td>96.9</td>\n",
       "      <td>18</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3180</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>24.3006</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.577</td>\n",
       "      <td>99.4</td>\n",
       "      <td>157</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6730</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>29.9012</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.591</td>\n",
       "      <td>98.5</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5780</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>21.2998</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M  So    Ed   Po1   Po2     LF    M.F  Pop    NW     U1   U2  Wealth  \\\n",
       "0  15.1   1   9.1   5.8   5.6  0.510   95.0   33  30.1  0.108  4.1    3940   \n",
       "1  14.3   0  11.3  10.3   9.5  0.583  101.2   13  10.2  0.096  3.6    5570   \n",
       "2  14.2   1   8.9   4.5   4.4  0.533   96.9   18  21.9  0.094  3.3    3180   \n",
       "3  13.6   0  12.1  14.9  14.1  0.577   99.4  157   8.0  0.102  3.9    6730   \n",
       "4  14.1   0  12.1  10.9  10.1  0.591   98.5   18   3.0  0.091  2.0    5780   \n",
       "\n",
       "   Ineq      Prob     Time  Crime  \n",
       "0  26.1  0.084602  26.2011    791  \n",
       "1  19.4  0.029599  25.2999   1635  \n",
       "2  25.0  0.083401  24.3006    578  \n",
       "3  16.7  0.015801  29.9012   1969  \n",
       "4  17.4  0.041399  21.2998   1234  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscrime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .info () -> returns important information about the dataset, such as the number of entries, estimation of missing data in each column, the type of each column and the memory used for allocating the dataframe.\n",
    "\n",
    "Note: By default, the numerical features in pandas allocate 32 or 64 bits (`float64` or` float32` and ʻint64` or ʻint32`), it is interesting, in the case of working with larger data sets that do not need this space in memory, to change the types of variables to `float16` and ʻint8`. This change is able to save a huge amount of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   M       47 non-null     float64\n",
      " 1   So      47 non-null     int64  \n",
      " 2   Ed      47 non-null     float64\n",
      " 3   Po1     47 non-null     float64\n",
      " 4   Po2     47 non-null     float64\n",
      " 5   LF      47 non-null     float64\n",
      " 6   M.F     47 non-null     float64\n",
      " 7   Pop     47 non-null     int64  \n",
      " 8   NW      47 non-null     float64\n",
      " 9   U1      47 non-null     float64\n",
      " 10  U2      47 non-null     float64\n",
      " 11  Wealth  47 non-null     int64  \n",
      " 12  Ineq    47 non-null     float64\n",
      " 13  Prob    47 non-null     float64\n",
      " 14  Time    47 non-null     float64\n",
      " 15  Crime   47 non-null     int64  \n",
      "dtypes: float64(12), int64(4)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "uscrime_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .describe () -> Calculation of several relevant statistics for numerical variables such as average, median, minimum and maximum values, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>47.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.857</td>\n",
       "      <td>0.340</td>\n",
       "      <td>10.564</td>\n",
       "      <td>8.500</td>\n",
       "      <td>8.023</td>\n",
       "      <td>0.561</td>\n",
       "      <td>98.302</td>\n",
       "      <td>36.617</td>\n",
       "      <td>10.113</td>\n",
       "      <td>0.095</td>\n",
       "      <td>3.398</td>\n",
       "      <td>5253.830</td>\n",
       "      <td>19.40</td>\n",
       "      <td>0.047</td>\n",
       "      <td>26.598</td>\n",
       "      <td>905.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.257</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.119</td>\n",
       "      <td>2.972</td>\n",
       "      <td>2.796</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2.947</td>\n",
       "      <td>38.071</td>\n",
       "      <td>10.283</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.845</td>\n",
       "      <td>964.909</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.023</td>\n",
       "      <td>7.087</td>\n",
       "      <td>386.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.700</td>\n",
       "      <td>4.500</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0.480</td>\n",
       "      <td>93.400</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.070</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2880.000</td>\n",
       "      <td>12.60</td>\n",
       "      <td>0.007</td>\n",
       "      <td>12.200</td>\n",
       "      <td>342.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.750</td>\n",
       "      <td>6.250</td>\n",
       "      <td>5.850</td>\n",
       "      <td>0.530</td>\n",
       "      <td>96.450</td>\n",
       "      <td>10.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>0.080</td>\n",
       "      <td>2.750</td>\n",
       "      <td>4595.000</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0.033</td>\n",
       "      <td>21.600</td>\n",
       "      <td>658.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.800</td>\n",
       "      <td>7.800</td>\n",
       "      <td>7.300</td>\n",
       "      <td>0.560</td>\n",
       "      <td>97.700</td>\n",
       "      <td>25.000</td>\n",
       "      <td>7.600</td>\n",
       "      <td>0.092</td>\n",
       "      <td>3.400</td>\n",
       "      <td>5370.000</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0.042</td>\n",
       "      <td>25.801</td>\n",
       "      <td>831.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>11.450</td>\n",
       "      <td>10.450</td>\n",
       "      <td>9.700</td>\n",
       "      <td>0.593</td>\n",
       "      <td>99.200</td>\n",
       "      <td>41.500</td>\n",
       "      <td>13.250</td>\n",
       "      <td>0.104</td>\n",
       "      <td>3.850</td>\n",
       "      <td>5915.000</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.054</td>\n",
       "      <td>30.451</td>\n",
       "      <td>1057.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.700</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12.200</td>\n",
       "      <td>16.600</td>\n",
       "      <td>15.700</td>\n",
       "      <td>0.641</td>\n",
       "      <td>107.100</td>\n",
       "      <td>168.000</td>\n",
       "      <td>42.300</td>\n",
       "      <td>0.142</td>\n",
       "      <td>5.800</td>\n",
       "      <td>6890.000</td>\n",
       "      <td>27.60</td>\n",
       "      <td>0.120</td>\n",
       "      <td>44.000</td>\n",
       "      <td>1993.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M      So      Ed     Po1     Po2      LF      M.F      Pop  \\\n",
       "count  47.000  47.000  47.000  47.000  47.000  47.000   47.000   47.000   \n",
       "mean   13.857   0.340  10.564   8.500   8.023   0.561   98.302   36.617   \n",
       "std     1.257   0.479   1.119   2.972   2.796   0.040    2.947   38.071   \n",
       "min    11.900   0.000   8.700   4.500   4.100   0.480   93.400    3.000   \n",
       "25%    13.000   0.000   9.750   6.250   5.850   0.530   96.450   10.000   \n",
       "50%    13.600   0.000  10.800   7.800   7.300   0.560   97.700   25.000   \n",
       "75%    14.600   1.000  11.450  10.450   9.700   0.593   99.200   41.500   \n",
       "max    17.700   1.000  12.200  16.600  15.700   0.641  107.100  168.000   \n",
       "\n",
       "           NW      U1      U2    Wealth   Ineq    Prob    Time     Crime  \n",
       "count  47.000  47.000  47.000    47.000  47.00  47.000  47.000    47.000  \n",
       "mean   10.113   0.095   3.398  5253.830  19.40   0.047  26.598   905.085  \n",
       "std    10.283   0.018   0.845   964.909   3.99   0.023   7.087   386.763  \n",
       "min     0.200   0.070   2.000  2880.000  12.60   0.007  12.200   342.000  \n",
       "25%     2.400   0.080   2.750  4595.000  16.55   0.033  21.600   658.500  \n",
       "50%     7.600   0.092   3.400  5370.000  17.60   0.042  25.801   831.000  \n",
       "75%    13.250   0.104   3.850  5915.000  22.75   0.054  30.451  1057.500  \n",
       "max    42.300   0.142   5.800  6890.000  27.60   0.120  44.000  1993.000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I used rounding to facilitate data visualization, remembering that as pandas is based on numpy operations\n",
    "# are easily applicable to all dataframe values.\n",
    "\n",
    "round(uscrime_df.describe(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inconsistencies in the types of variables\n",
    "\n",
    "Observing the description of the variables, their data structures and the values ​​of the statistics, it is observed that we have an inconsistency with the `So` feature. This is a categorical feature, which indicates whether the entry is from a southern state or not, so calculations such as average, standard deviation and quartiles do not make much sense. In this case, it is necessary to make a change in the type of the variable to categorical and apply the .describe () method again. It will be possible to observe an adaptation of pandas to treat this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>So</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        So\n",
       "count   47\n",
       "unique   2\n",
       "top      0\n",
       "freq    31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method .astype() to transform data type to category\n",
    "uscrime_df[['So']].astype('category').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the data type to categorical, we can observe the change in the statistics calculated by the `.describe ()` method, I can now analyze how many unique values ​​the variable has (in this case, 0 and 1), which is the most frequent value ( top = 0) and its frequency (31 occurrences in 47, approximately 65.96%).\n",
    "As noted, there are only two categories for this variable, so I will keep this column as an integer type, since it can be used as a feature in the development of the predictive model.\n",
    "In cases where more category options occur, we can use methodologies such as ʻone hot encoding` or `get_dummies` to transform these features into numeric features, where new columns would be created in the data frame, each representing a category (remembering to create n-1 new columns so that there is no redundancy affecting the model's performance). The idea of ​​this methodology is that when creating numerical categories, the prediction models do not consider higher numbers as more important and with the creation of a column for each category, I guarantee that the possible values ​​are only 1 (if it belongs to the category) and 0 (if not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment of Missing Data\n",
    "\n",
    "This is a very important stage of exploratory data analysis, in this case there is no occurrence of missing data, but if there were, we would have to think about a strategy to treat them. Here are some possibilities:\n",
    "\n",
    "- If there is a small amount in relation to the total volume of data, I can simply delete the entries with missing data (remembering that the definition of what would be 'little significant' varies from case to case).\n",
    "- We can use statistics to fill in, such as average, median, minimum and maximum values.\n",
    "- We can use a business rule to fill out.\n",
    "- We can rely on other variables to obtain these values, both through direct relationships and through predictive models.\n",
    "\n",
    "Anyway, there are probably other ways to analyze and fill in missing data, this being a peculiar analysis of each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value? -> No\n"
     ]
    }
   ],
   "source": [
    "# As a quick analysis of the presence or absence of missing data, I can run the following line of code:\n",
    "\n",
    "has_nan = any(uscrime_df.isna().sum())\n",
    "print(f\"Is there any missing value? -> {'Yes' if has_nan else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of correlation between variables\n",
    "\n",
    "One effective way to observe how variables are related is to analyze the correlation between them. Pandas already has a native .corr () method that when applied to the data frame, returns how the numeric variables relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.584</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So</th>\n",
       "      <td>0.584</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ed</th>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Po1</th>\n",
       "      <td>-0.506</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>0.483</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.526</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Po2</th>\n",
       "      <td>-0.513</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.794</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF</th>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.106</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M.F</th>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.514</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>-0.281</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NW</th>\n",
       "      <td>0.593</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-0.665</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.341</td>\n",
       "      <td>-0.327</td>\n",
       "      <td>0.095</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1</th>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U2</th>\n",
       "      <td>-0.245</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wealth</th>\n",
       "      <td>-0.670</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.092</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ineq</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.769</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.677</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.884</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prob</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.347</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>0.465</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M     So     Ed    Po1    Po2     LF    M.F    Pop     NW     U1  \\\n",
       "M       1.000  0.584 -0.530 -0.506 -0.513 -0.161 -0.029 -0.281  0.593 -0.224   \n",
       "So      0.584  1.000 -0.703 -0.373 -0.376 -0.505 -0.315 -0.050  0.767 -0.172   \n",
       "Ed     -0.530 -0.703  1.000  0.483  0.499  0.561  0.437 -0.017 -0.665  0.018   \n",
       "Po1    -0.506 -0.373  0.483  1.000  0.994  0.121  0.034  0.526 -0.214 -0.044   \n",
       "Po2    -0.513 -0.376  0.499  0.994  1.000  0.106  0.023  0.514 -0.219 -0.052   \n",
       "LF     -0.161 -0.505  0.561  0.121  0.106  1.000  0.514 -0.124 -0.341 -0.229   \n",
       "M.F    -0.029 -0.315  0.437  0.034  0.023  0.514  1.000 -0.411 -0.327  0.352   \n",
       "Pop    -0.281 -0.050 -0.017  0.526  0.514 -0.124 -0.411  1.000  0.095 -0.038   \n",
       "NW      0.593  0.767 -0.665 -0.214 -0.219 -0.341 -0.327  0.095  1.000 -0.156   \n",
       "U1     -0.224 -0.172  0.018 -0.044 -0.052 -0.229  0.352 -0.038 -0.156  1.000   \n",
       "U2     -0.245  0.072 -0.216  0.185  0.169 -0.421 -0.019  0.270  0.081  0.746   \n",
       "Wealth -0.670 -0.637  0.736  0.787  0.794  0.295  0.180  0.308 -0.590  0.045   \n",
       "Ineq    0.639  0.737 -0.769 -0.631 -0.648 -0.270 -0.167 -0.126  0.677 -0.064   \n",
       "Prob    0.361  0.531 -0.390 -0.473 -0.473 -0.250 -0.051 -0.347  0.428 -0.007   \n",
       "Time    0.115  0.067 -0.254  0.103  0.076 -0.124 -0.428  0.464  0.230 -0.170   \n",
       "Crime  -0.089 -0.091  0.323  0.688  0.667  0.189  0.214  0.337  0.033 -0.050   \n",
       "\n",
       "           U2  Wealth   Ineq   Prob   Time  Crime  \n",
       "M      -0.245  -0.670  0.639  0.361  0.115 -0.089  \n",
       "So      0.072  -0.637  0.737  0.531  0.067 -0.091  \n",
       "Ed     -0.216   0.736 -0.769 -0.390 -0.254  0.323  \n",
       "Po1     0.185   0.787 -0.631 -0.473  0.103  0.688  \n",
       "Po2     0.169   0.794 -0.648 -0.473  0.076  0.667  \n",
       "LF     -0.421   0.295 -0.270 -0.250 -0.124  0.189  \n",
       "M.F    -0.019   0.180 -0.167 -0.051 -0.428  0.214  \n",
       "Pop     0.270   0.308 -0.126 -0.347  0.464  0.337  \n",
       "NW      0.081  -0.590  0.677  0.428  0.230  0.033  \n",
       "U1      0.746   0.045 -0.064 -0.007 -0.170 -0.050  \n",
       "U2      1.000   0.092  0.016 -0.062  0.101  0.177  \n",
       "Wealth  0.092   1.000 -0.884 -0.555  0.001  0.441  \n",
       "Ineq    0.016  -0.884  1.000  0.465  0.102 -0.179  \n",
       "Prob   -0.062  -0.555  0.465  1.000 -0.436 -0.427  \n",
       "Time    0.101   0.001  0.102 -0.436  1.000  0.150  \n",
       "Crime   0.177   0.441 -0.179 -0.427  0.150  1.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case, I created a new data frame to receive the correlation between variables\n",
    "\n",
    "uscrime_correlation_df = round(uscrime_df.corr(), 3)\n",
    "uscrime_correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of the heat map for the correlations between numerical variables in the data frame.\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(uscrime_correlation_df, center=0, cmap='seismic');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M        -0.089\n",
       "So       -0.091\n",
       "Ed        0.323\n",
       "Po1       0.688\n",
       "Po2       0.667\n",
       "LF        0.189\n",
       "M.F       0.214\n",
       "Pop       0.337\n",
       "NW        0.033\n",
       "U1       -0.050\n",
       "U2        0.177\n",
       "Wealth    0.441\n",
       "Ineq     -0.179\n",
       "Prob     -0.427\n",
       "Time      0.150\n",
       "Name: Crime, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_with_crime = uscrime_correlation_df.loc['Crime'][uscrime_correlation_df.columns != 'Crime']\n",
    "correlation_with_crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important notes:\n",
    "\n",
    "Considering the correlations and heat map, it is observed that the variables `Po1` and` Po2` are those that have the highest correlations with the target variable (respectively 0.688 and 0.667), it is also observed that these variables have a correlation of almost 1 among them (0.994), this means that I can use only one of them in my predictive model, thus reducing the dimension of the problem. In this case, I will use the variable `Po1` which has the highest correlation with the target variable.\n",
    "The variables `M`,` So`, `NW` and ʻU1` show correlations less than 0.1 and -0.1 so they will not be considered in the development of the predictive model.\n",
    "In this step, I will use object-oriented development to develop the predictive model, the idea is that with this modeling, it is possible to create and compare models, in order to obtain the best possible model considering the adopted criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of the CrimeRatePredictor class\n",
    "\n",
    "This class will be used to abstract all stages of the development of the prediction model, the idea is to make a development focused on reusability, scalability and maintenance. Also making a good definition of each method, it is possible to perform unit tests in a very simple and direct way.\n",
    "\n",
    "I will comment a little on the most important methods of this class:\n",
    "\n",
    "- `feature_selection ()` - This method defines which features will be used in the predictive model. At first, I used the correlation analysis, taking as a parameter a cut factor.\n",
    "\n",
    "- `transform_data_with_selected_features ()` - This method applies the features selected in the data frame, obtaining the specific data frame that will be used in the predictive model. There is also a static method that will be used to transform new data.\n",
    "\n",
    "- `split_data_into_train_test_part ()` - Method used to partition the original data into training data and test data so that I can validate the model by calculating metrics that can be compared.\n",
    "\n",
    "- `fit_model_to_predict ()` - Method responsible for calibrating the model. At first I used linear regression.\n",
    "\n",
    "- `make_predictions_with_test_data ()` - Method responsible for calculating predicting results using test data in order to be used in the calculation of validation metrics.\n",
    "\n",
    "- `calculate_model_metric ()` - This function calculates the evaluation metrics of the models using the predictions of the test data. The calculated metric is allocated to an attribute, this attribute will be used in the ordering methods, allowing objects of the class to be ordered when arranged in a collection.\n",
    "\n",
    "- `@ total_ordering`,` __eq __ () `and` __lt __ () `- Define methods that allow objects of this class to be sorted according to some specific criteria. In this case I will use the metric.\n",
    "\n",
    "\n",
    "# Metric used: explained_variance_score:\n",
    "\n",
    "This metric explains the dispersion of errors in a given data set. The closer to 1, the better the model, indicating better squares of the standard deviations of the errors.\n",
    "\n",
    "[referencia 1:](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)  \n",
    "[referencia 2:](https://books.google.com.br/books?id=7S6WDwAAQBAJ&pg=PA332&lpg=PA332&dq=explained_variance_score&source=bl&ots=awF03vf-ai&sig=ACfU3U0TjsTsxfY6KxJfUFuHEUGpR3IM4w&hl=pt-BR&sa=X&ved=2ahUKEwiS2M3TqK_qAhXmGbkGHaNAB4oQ6AEwDnoECAoQAQ#v=onepage&q=explained_variance_score&f=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@total_ordering\n",
    "class CrimeRatePredictor(object):\n",
    "    \"\"\"\n",
    "    This class will be used as a model for specific child classes for each considered predictive model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, crime_df):\n",
    "        \n",
    "        # This class will delete 'Po2' from original data frame once we decided didn't consider it in our analysis.\n",
    "        self.crime_df = crime_df.copy()\n",
    "        del (self.crime_df['Po2'])\n",
    "        \n",
    "        # List of features that will be used according some criteria\n",
    "        self.corr_factor = 0\n",
    "        self.features_to_use = []\n",
    "        \n",
    "        # Target name in case of use it in other methods\n",
    "        self.target_name = 'Crime'\n",
    "        \n",
    "        # Complete data from target variable\n",
    "        self.target_data = self.crime_df[self.target_name]\n",
    "        \n",
    "        # Attribute to allocate complete data \n",
    "        self.complete_x_data = self.crime_df.drop(columns='Crime')\n",
    "        \n",
    "        # Attributes that will be used into train x test split\n",
    "        self.x_train = 'This attribute is not defined yet'\n",
    "        self.x_test = 'This attribute is not defined yet'\n",
    "        self.y_train = 'This attribute is not defined yet'\n",
    "        self.y_test = 'This attribute is not defined yet'\n",
    "        \n",
    "        # Number that ensures that the numerical experiment can be reproduced.\n",
    "        self.random_seed = 42\n",
    "        \n",
    "        # Infos about prediction model.\n",
    "        self.model_name = 'Linear Regression'\n",
    "        self.model = LinearRegression()\n",
    "        self.model_metric = 'This attribute is not defined yet'\n",
    "        \n",
    "        # Values predicted using x_test to validate the model.\n",
    "        self.y_test_pred = 'This attribute is not defined yet'\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def model_info(self):\n",
    "        \n",
    "        complete_info =  f\"Model: {self.model_name} \"\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Correlation Factor: {self.corr_factor} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Number of features used: {len(self.features_to_use)} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Metric - Explained Variance Score: {round(self.model_metric, 3)}'\n",
    "        return complete_info\n",
    "    \n",
    "    @property\n",
    "    def print_shape(self):\n",
    "        \"\"\"\n",
    "        Method to print the number of rows and columns.\n",
    "        \"\"\"\n",
    "        print(f'Number of lines: {self.crime_df.shape[0]}')\n",
    "        print(f'Number of columns: {self.crime_df.shape[1]}')\n",
    "        \n",
    "    @property\n",
    "    def print_column_names(self):\n",
    "        \"\"\"\n",
    "        Method to print column names of the original data frame.\n",
    "        \"\"\"\n",
    "        print('Column names:')\n",
    "        \n",
    "        for column in self.crime_df.columns:\n",
    "            \n",
    "            print(f'             {column} - type: {self.crime_df[column].dtype}')\n",
    "        \n",
    "    def show_dataframe_information(self):\n",
    "        \"\"\"\n",
    "        Show information about data frame used to develop this model.\n",
    "        \"\"\"\n",
    "        print('========= Start Data Frame Information ==========')\n",
    "        print('\\n')\n",
    "        self.print_shape\n",
    "        self.print_column_names\n",
    "        print('\\n')\n",
    "        print('========= Finish Data Frame Information ==========')\n",
    "        \n",
    "   \n",
    "    def feature_selection(self, corr_factor: float) -> list:\n",
    "        \"\"\"\n",
    "        Method based on a correlation factor to decide which features will be used to implement a predictive model.\n",
    "        \n",
    "        args:\n",
    "        \n",
    "            corr_factor: float -> factor that will be used to select most influent features. In this case, features that\n",
    "                                  presents correlation with target greater than corr_factor or less than (-corr_factor).\n",
    "                                  \n",
    "        return: \n",
    "            \n",
    "            self.features_to_use: list -> List of features that will be used defined by corr_factor criteria.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.corr_factor = corr_factor\n",
    "        # Create the correlational data frame.\n",
    "        crime_df_corr = self.crime_df.corr()\n",
    "        \n",
    "        # Obtain the conditional to filter the correlation data frame considering the corr_factor\n",
    "        evaluate_corr_factor_conditional = (crime_df_corr[self.target_name] >= corr_factor) \\\n",
    "                                           | (crime_df_corr[self.target_name] <= -corr_factor)\n",
    "        \n",
    "        # Select all features that achieve the corr_factor test.\n",
    "        self.features_to_use = crime_df_corr[evaluate_corr_factor_conditional].index\n",
    "        \n",
    "        # Drop target column (Crime) and transform to list.\n",
    "        self.features_to_use = self.features_to_use.drop(self.target_name).tolist()\n",
    "        \n",
    "        return self.features_to_use\n",
    "        \n",
    "    def transform_data_with_selected_features(self):\n",
    "        \"\"\"\n",
    "        This method get data just using the selected features\n",
    "        \n",
    "        return:\n",
    "            \n",
    "            self.complete_x_data: pd.DataFrame -> Data Frame containing just selected features\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x_train = self.x_train[self.features_to_use]\n",
    "        self.x_test = self.x_test[self.features_to_use]\n",
    "        print('x_train and x_test were transformed using feature selection.')\n",
    "        \n",
    "        \n",
    "    def split_data_into_train_test_part(self, split_factor=0.3) -> str:\n",
    "        \"\"\"\n",
    "        Method used to divide complete data into train/test data to use to fit and validate the predictive model.\n",
    "        \n",
    "        args:\n",
    "            \n",
    "            split_factor: float -> Value that deifne the partition between train and test. This factor refers to test quantity.\n",
    "                          So, if split_factor equals 0.3 means that 30% of data will be used to test.\n",
    "                          \n",
    "        return:\n",
    "        \n",
    "            message: str -> Message that means everything works well, it's recomended that if an user wants to see and explore\n",
    "                     train and test data, just access it by object attributes.\n",
    "        \"\"\"\n",
    "        \n",
    "        message = 'Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.'\n",
    "        \n",
    "        splitted_results = train_test_split(self.complete_x_data, self.target_data, random_state=self.random_seed\\\n",
    "                                            , test_size=split_factor)\n",
    "        \n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = splitted_results\n",
    "        \n",
    "        print(message)\n",
    "    \n",
    "    def fit_model_to_predict(self):\n",
    "        \"\"\"\n",
    "        Method do calibrate the prediction model using x_train\n",
    "        \"\"\"\n",
    "        self.model.fit(self.x_train, self.y_train)\n",
    "        print(f'The {self.model_name} was fitted and is ready to use!')\n",
    "        \n",
    "    def make_predictions_with_test_data(self):\n",
    "        \"\"\"\n",
    "        Method to predict results using x_test data in order to validade the model and server as input into metrics \n",
    "        calculations.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.y_test_pred = self.model.predict(self.x_test)\n",
    "        print(f'Results were predicted using x_test data in order to validade the model.')\n",
    "        \n",
    "    def calculate_model_metric(self):\n",
    "        \"\"\"\n",
    "        Method to calculate the performance of the model that will be used to compare with others and make it orderable when\n",
    "        within a collection.\n",
    "        \"\"\"\n",
    "        self.model_metric = explained_variance_score(self.y_test, self.y_test_pred)\n",
    "        return self.model_metric\n",
    "    \n",
    "\n",
    "    def tranform_external_data_with_selected_features(self, external_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform external data using the selected features\n",
    "        \n",
    "        args:\n",
    "        \n",
    "            external_data: pd.DataFrame -> New data to transform using the selected features.\n",
    "            \n",
    "        return:\n",
    "        \n",
    "            Modified data frame considering just selected features.\n",
    "        \n",
    "        \"\"\"\n",
    "        return external_data[self.features_to_use]\n",
    "    \n",
    "\n",
    "    def make_predictions_with_external_data(self, external_data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions using external data, remember that before this step, apply the method transform_external_data_with_\n",
    "        selected_features.\n",
    "        args:\n",
    "        \n",
    "            external_data: pd.DataFrame -> External, transformed data frame.\n",
    "            \n",
    "        return:\n",
    "        \n",
    "            numpy array with predictions for one or more entries.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.model.predict(external_data)\n",
    "\n",
    "    # dunder methods to make object orderable into collections.\n",
    "    def __eq__(self, other):\n",
    "        \n",
    "        return self.model_metric == other.model_metric\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        \n",
    "        return self.model_metric < other.model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__At this point, I have a class capable of creating objects that represent a prediction model for the present data and, uscrime.txt. Taking advantage of the reusability of the code, I can easily create different models by varying the cut-off value for the correlation, ordering them in a list thus obtaining the model with the best metric.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_crime_model(corr: float) -> CrimeRatePredictor:\n",
    "    \n",
    "    print(f\"Creating an object with correlation factor = {corr}\")\n",
    "    \n",
    "    # Pipeline to create a PredictCrimeModel\n",
    "    \n",
    "    # Create the object with uscrime data frame\n",
    "    PredictCrimeModel = CrimeRatePredictor(uscrime_df)\n",
    "    \n",
    "    # Split data into train and test data with 0.3 (30% rate)\n",
    "    PredictCrimeModel.split_data_into_train_test_part(0.3)\n",
    "    \n",
    "    # Select features considering the correlation value\n",
    "    PredictCrimeModel.feature_selection(corr)\n",
    "    \n",
    "    # Tranform data using selected features\n",
    "    PredictCrimeModel.transform_data_with_selected_features()\n",
    "    \n",
    "    # Fit the model using train data\n",
    "    PredictCrimeModel.fit_model_to_predict()\n",
    "    \n",
    "    # Make predictions with test data\n",
    "    PredictCrimeModel.make_predictions_with_test_data()\n",
    "    \n",
    "    # Calculate the metric based on Explained variance score\n",
    "    PredictCrimeModel.calculate_model_metric()\n",
    "    print(PredictCrimeModel.model_info)\n",
    "    print('\\n')\n",
    "    \n",
    "    return PredictCrimeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating an object with correlation factor = 0\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0 -> Number of features used: 14 -> Metric - Explained Variance Score: 0.779\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.1\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.1 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.716\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.2\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.2 -> Number of features used: 6 -> Metric - Explained Variance Score: 0.623\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.3\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.3 -> Number of features used: 5 -> Metric - Explained Variance Score: 0.6\n",
      "\n",
      "\n",
      "Creating an object with correlation factor = 0.4\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Correlation Factor: 0.4 -> Number of features used: 3 -> Metric - Explained Variance Score: 0.606\n",
      "\n",
      "\n",
      "Best model information: \n",
      "Model: Linear Regression -> Correlation Factor: 0 -> Number of features used: 14 -> Metric - Explained Variance Score: 0.779\n"
     ]
    }
   ],
   "source": [
    "# In this step I'll create differente models using different\n",
    "\n",
    "correlations = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "\n",
    "# Create a list of CrimeRatePredictor objects:\n",
    "\n",
    "crime_predictors = [create_prediction_crime_model(corr) for corr in correlations]\n",
    "\n",
    "crime_predictors = sorted(crime_predictors)\n",
    "\n",
    "best_model_corr = crime_predictors[-1]\n",
    "\n",
    "print('Best model information: ')\n",
    "print(best_model_corr.model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production model\n",
    "\n",
    "At this point, we were able to evaluate different models considering different sets of features.\n",
    "Through the object-oriented paradigm, we are able to easily generate the objects that store the model and order them according to the metric, thus obtaining the best model with the premises considered.\n",
    "The best model uses all the features and obtains a score of 0.78 / 1 considering the metric ʻexplained variance score`. It is possible to deliver a solution to a possible customer now, generating value and giving you the peace of mind to continue working on improving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model to make new predictions\n",
    "\n",
    "We will use the best model so far, to calculate the crime rate with the additional point provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.64</td>\n",
       "      <td>94.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3200</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M  So    Ed   Po1   Po2    LF   M.F  Pop   NW    U1   U2  Wealth  Ineq  \\\n",
       "0  14.0   0  10.0  12.0  15.5  0.64  94.0  150  1.1  0.12  3.6    3200  20.1   \n",
       "\n",
       "   Prob  Time  \n",
       "0  0.04  39.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_calculate = {'M':[14.0],\n",
    "                     'So': [0],\n",
    "                     'Ed': [10.0],\n",
    "                     'Po1': [12.0],\n",
    "                     'Po2': [15.5],\n",
    "                     'LF': [0.640],\n",
    "                     'M.F': [94.0],\n",
    "                     'Pop': [150],\n",
    "                     'NW': [1.1],\n",
    "                     'U1': [0.120],\n",
    "                     'U2': [3.6],\n",
    "                     'Wealth': [3200],\n",
    "                     'Ineq': [20.1],\n",
    "                     'Prob': [0.04],\n",
    "                     'Time': [39.0]}\n",
    "\n",
    "data_df = pd.DataFrame(data_to_calculate)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predict value using new data is 1024.44\n"
     ]
    }
   ],
   "source": [
    "transformed_data = best_model_corr.tranform_external_data_with_selected_features(data_df)\n",
    "predict_value_corr = best_model_corr.make_predictions_with_external_data(transformed_data)\n",
    "\n",
    "\n",
    "print(f'The predict value using new data is {round(predict_value_corr[0], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inheritance and Polymorphism\n",
    "\n",
    "As the model was built, we can easily add and change functionality, correct possible errors without affecting the whole and work well in a team where each team member can focus on developing or improving a specific functionality. A very interesting concept that can be applied in object-oriented development is inheritance and polymorphism. We can build a class that inherits the characteristics (attributes and methods) of the current class, changing only the functionality of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting features with RFE\n",
    "\n",
    "RFE is a model present in the scikit learn module and is used to define which variables have the greatest impact on the predictive model. The variables are eliminated one by one until they reach the stipulated value. In this case, I will redefine the method of selecting features of the CrimeRatePredictor class and make the selection by eliminating 1 to 5 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrimeRatePredictorUsingRFE(CrimeRatePredictor):\n",
    "    \n",
    "    def __init__(self, crime_df):\n",
    "        \n",
    "        super().__init__(crime_df)\n",
    "        self.n_features_to_remove = None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def model_info(self):\n",
    "        \n",
    "        complete_info =  f\"Model: {self.model_name} \"\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Number of features to remove: {self.n_features_to_remove} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Number of features used: {len(self.features_to_use)} '\n",
    "        complete_info += '-> '\n",
    "        complete_info += f'Metric - Explained Variance Score: {round(self.model_metric, 3)}'\n",
    "        return complete_info\n",
    "    \n",
    "    def feature_selection(self, n_removed_features=None) -> list:\n",
    "        \"\"\"\n",
    "        Method based on a RFE model to decide which features will be used to implement a predictive model.\n",
    "        \n",
    "        args:\n",
    "        \n",
    "            n_removed_features: int -> Define the number of features that will be eliminated.\n",
    "                                  \n",
    "        return: \n",
    "            \n",
    "            self.features_to_use: list -> List of features that will be used defined by corr_factor criteria.\n",
    "        \"\"\"\n",
    "        self.n_features_to_remove = n_removed_features\n",
    "        \n",
    "        # Define RFE model using Linear Regression to calculate.\n",
    "        # n_removed_features define the number of features that will be eliminated.\n",
    "        rfe = RFE(self.model, n_features_to_select=len(self.x_train.columns) - n_removed_features)\n",
    "            \n",
    "        # Fit RFE model using x_train and y_train\n",
    "        rfe.fit(self.x_train, self.y_train)\n",
    "            \n",
    "        # Get info from RFE\n",
    "        rfe_info =  pd.DataFrame({'column': self.x_train.columns,\n",
    "                                      'bool': rfe.get_support()})\n",
    "        only_true_rfe = rfe_info[rfe_info['bool'] == True]\n",
    "        self.features_to_use = only_true_rfe['column'].tolist()\n",
    "            \n",
    "        \n",
    "        return self.features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_crime_model_rfe(n_features: float) -> CrimeRatePredictorUsingRFE:\n",
    "    \n",
    "    print(f\"Creating an object with n number of removed features = {n_features}\")\n",
    "    \n",
    "    # Pipeline to create a PredictCrimeModel\n",
    "    \n",
    "    # Create the object with uscrime data frame\n",
    "    PredictCrimeModel = CrimeRatePredictorUsingRFE(uscrime_df)\n",
    "    \n",
    "    # Split data into train and test data with 0.3 (30% rate)\n",
    "    PredictCrimeModel.split_data_into_train_test_part(0.3)\n",
    "    \n",
    "    # Select features considering the correlation value\n",
    "    PredictCrimeModel.feature_selection(n_features)\n",
    "    \n",
    "    # Tranform data using selected features\n",
    "    PredictCrimeModel.transform_data_with_selected_features()\n",
    "    \n",
    "    # Fit the model using train data\n",
    "    PredictCrimeModel.fit_model_to_predict()\n",
    "    \n",
    "    # Make predictions with test data\n",
    "    PredictCrimeModel.make_predictions_with_test_data()\n",
    "    \n",
    "    # Calculate the metric based on Explained variance score\n",
    "    PredictCrimeModel.calculate_model_metric()\n",
    "    print(PredictCrimeModel.model_info)\n",
    "    print('\\n')\n",
    "    \n",
    "    return PredictCrimeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating an object with n number of removed features = 1\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 1 -> Number of features used: 13 -> Metric - Explained Variance Score: 0.766\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 2\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 2 -> Number of features used: 12 -> Metric - Explained Variance Score: 0.766\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 3\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 3 -> Number of features used: 11 -> Metric - Explained Variance Score: 0.818\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 4\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 4 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.818\n",
      "\n",
      "\n",
      "Creating an object with n number of removed features = 5\n",
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n",
      "x_train and x_test were transformed using feature selection.\n",
      "The Linear Regression was fitted and is ready to use!\n",
      "Results were predicted using x_test data in order to validade the model.\n",
      "Model: Linear Regression -> Number of features to remove: 5 -> Number of features used: 9 -> Metric - Explained Variance Score: 0.815\n",
      "\n",
      "\n",
      "Best model information: \n",
      "Model: Linear Regression -> Number of features to remove: 4 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.818\n"
     ]
    }
   ],
   "source": [
    "# In this step I'll create differente models using different number of features to remove.\n",
    "\n",
    "n_features_to_remove = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "# Create a list of CrimeRatePredictorUsingRFE objects:\n",
    "\n",
    "crime_predictors = [create_prediction_crime_model_rfe(n) for n in n_features_to_remove]\n",
    "\n",
    "crime_predictors = sorted(crime_predictors)\n",
    "\n",
    "best_model_rfe = crime_predictors[-2]\n",
    "\n",
    "print('Best model information: ')\n",
    "print(best_model_rfe.model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used in the best correlation model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M,So,Ed,Po1,LF,M.F,Pop,NW,U1,U2,Wealth,Ineq,Prob,Time'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used in the rfe model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M,Ed,Po1,LF,M.F,U1,U2,Ineq,Prob,Time'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation model - explained_variance_score: 0.779\n",
      "RFE model - explained_variance_score: 0.818\n"
     ]
    }
   ],
   "source": [
    "print('Features used in the best correlation model:')\n",
    "display(','.join(best_model_corr.features_to_use))\n",
    "\n",
    "print('Features used in the rfe model:')\n",
    "display(','.join(best_model_rfe.features_to_use))\n",
    "\n",
    "print(f'Correlation model - explained_variance_score: {round(best_model_corr.model_metric, 3)}')\n",
    "print(f'RFE model - explained_variance_score: {round(best_model_rfe.model_metric, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result for the model that selects the features through the highest correlations considered all the features for defining the linear regression. Applying the selection of features by RFE, it is observed that the best model eliminated 4 features, among them `Wealth` and` Pop` which, although they present considerable correlations with the target variable, impair the linear regression.\n",
    "With that, in addition to the performance gain from `0.779` to` 0.818`, I still got a more performance model that performs the calculations considering 4 fewer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predict value using new data is 1222.06\n"
     ]
    }
   ],
   "source": [
    "transformed_data = best_model_rfe.tranform_external_data_with_selected_features(data_df)\n",
    "predict_value_rfe = best_model_rfe.make_predictions_with_external_data(transformed_data)\n",
    "\n",
    "\n",
    "print(f'The predict value using new data is {round(predict_value_rfe[0], 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation model - Valor predito: 1024.44\n",
      "RFE model - Valor  predito: 1222.06\n"
     ]
    }
   ],
   "source": [
    "print(f'Correlation model - Valor predito: {round(predict_value_corr[0], 2)}')\n",
    "print(f'RFE model - Valor  predito: {round(predict_value_rfe[0], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrated the power of the object-oriented paradigm applied to a data science project, where in a simple way it is possible to analyze each part of the code in search of better performance and better predictive performance.\n",
    "Other analyzes that can be done:\n",
    "\n",
    "- Application of dimensionality reduction using PCA\n",
    "- Inclusion of other metrics for model analysis such as `Mean Square Error` or` Median Absolut Error`. Remembering that to do this, just follow the concepts of inheritance and polymorphism to create another class, varying only the method that calculates these metrics.\n",
    "- Analysis of other regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model Information: \n",
      "Model: Linear Regression -> Number of features to remove: 4 -> Number of features used: 10 -> Metric - Explained Variance Score: 0.818\n"
     ]
    }
   ],
   "source": [
    "print('The best model Information: ')\n",
    "print(best_model_rfe.model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final note:\n",
    "\n",
    "Another important point of this form of development is the possibility of executing unit tests for each step of the code, ensuring that quality is guaranteed, minimizing rework and future errors. Therefore, we can proceed with a calmer mind to the next steps.\n",
    "\n",
    "Questions like:\n",
    "\n",
    "- Does my model select the features correctly?\n",
    "- Is my division between test and training data being done correctly?\n",
    "\n",
    "Among others, they can be asked and answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was splitted, to analyze the values, access the attributes: x_train, x_test, y_train, y_test.\n"
     ]
    }
   ],
   "source": [
    "# Pipeline to create a PredictCrimeModel\n",
    "    \n",
    "# Create the object with uscrime data frame\n",
    "PredictCrimeModel = CrimeRatePredictor(uscrime_df)\n",
    "    \n",
    "# Split data into train and test data with 0.3 (30% rate)\n",
    "PredictCrimeModel.split_data_into_train_test_part(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert PredictCrimeModel.feature_selection(0.4) == ['Po1', 'Wealth', 'Prob']\n",
    "assert round(len(PredictCrimeModel.x_train) / len(uscrime_df), 1) == 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Assert that returns nothing passed the test = D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
